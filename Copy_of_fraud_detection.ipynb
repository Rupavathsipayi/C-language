{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 1399887,
          "sourceType": "datasetVersion",
          "datasetId": 817870
        }
      ],
      "dockerImageVersionId": 30840,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rupavathsipayi/C-language/blob/main/Copy_of_fraud_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "kartik2112_fraud_detection_path = kagglehub.dataset_download('kartik2112/fraud-detection')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "FNL6bz8Cko3R"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read & Load Data"
      ],
      "metadata": {
        "id": "uI812ttkko3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from mpl_toolkits.mplot3d import Axes3D  # For 3D plots\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:18:06.186442Z",
          "iopub.execute_input": "2025-02-15T22:18:06.186696Z",
          "iopub.status.idle": "2025-02-15T22:18:22.254707Z",
          "shell.execute_reply.started": "2025-02-15T22:18:06.186666Z",
          "shell.execute_reply": "2025-02-15T22:18:22.25404Z"
        },
        "id": "7v0F699hko3a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/fraudTrain.csv')\n",
        "t_df = pd.read_csv('/content/fraudTest.csv')\n",
        "df"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:18:27.124495Z",
          "iopub.execute_input": "2025-02-15T22:18:27.124794Z",
          "iopub.status.idle": "2025-02-15T22:18:41.270675Z",
          "shell.execute_reply.started": "2025-02-15T22:18:27.124772Z",
          "shell.execute_reply": "2025-02-15T22:18:41.269694Z"
        },
        "id": "1qIEAAZiko3a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df['is_fraud'].value_counts()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:18:41.271792Z",
          "iopub.execute_input": "2025-02-15T22:18:41.272104Z",
          "iopub.status.idle": "2025-02-15T22:18:41.293109Z",
          "shell.execute_reply.started": "2025-02-15T22:18:41.27208Z",
          "shell.execute_reply": "2025-02-15T22:18:41.292334Z"
        },
        "id": "CZUGelCnko3b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "PLf-q0i7ko3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df):\n",
        "    # Drop unnecessary columns\n",
        "    df = df.drop(['cc_num', 'trans_date_trans_time', 'first', 'last', 'dob', 'street', 'trans_num', 'unix_time', 'merchant'], axis=1)\n",
        "\n",
        "    # Handle outliers for 'amt' and 'city_pop'\n",
        "    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "    for col in numerical_columns:\n",
        "        if col in ['amt', 'city_pop']:\n",
        "            Q1 = df[col].quantile(0.25)\n",
        "            Q3 = df[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)\n",
        "\n",
        "    # Encode categorical variables\n",
        "    label_encoder = LabelEncoder()\n",
        "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
        "    for col in categorical_columns:\n",
        "        df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "    # Convert gender to binary\n",
        "    df['gender'] = df['gender'].apply(lambda x: 1 if x == 'M' else 0)\n",
        "\n",
        "    # Normalize numerical features\n",
        "    scaler = MinMaxScaler()\n",
        "    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
        "\n",
        "    return df_scaled\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:18:41.294689Z",
          "iopub.execute_input": "2025-02-15T22:18:41.294895Z",
          "iopub.status.idle": "2025-02-15T22:18:41.308745Z",
          "shell.execute_reply.started": "2025-02-15T22:18:41.294876Z",
          "shell.execute_reply": "2025-02-15T22:18:41.307874Z"
        },
        "id": "gaqQdfkJko3c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_preprocessed = preprocess_data(df)\n",
        "t_df_preprocessed = preprocess_data(t_df)\n",
        "\n",
        "print(df_preprocessed.head())\n",
        "print(t_df_preprocessed.head())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:18:41.310084Z",
          "iopub.execute_input": "2025-02-15T22:18:41.310386Z",
          "iopub.status.idle": "2025-02-15T22:18:44.137159Z",
          "shell.execute_reply.started": "2025-02-15T22:18:41.310356Z",
          "shell.execute_reply": "2025-02-15T22:18:44.136212Z"
        },
        "id": "qvvh25epko3c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_preprocessed.isna().sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:18:44.138165Z",
          "iopub.execute_input": "2025-02-15T22:18:44.138483Z",
          "iopub.status.idle": "2025-02-15T22:18:44.196073Z",
          "shell.execute_reply.started": "2025-02-15T22:18:44.138458Z",
          "shell.execute_reply": "2025-02-15T22:18:44.195384Z"
        },
        "id": "yMSqcNoJko3d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# check coulmns type and missing values and shape of data\n",
        "df_preprocessed.info()\n",
        "# this mean nulls = zero\n",
        "# we need to convert any object to numrical value"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:18:44.196756Z",
          "iopub.execute_input": "2025-02-15T22:18:44.196995Z",
          "iopub.status.idle": "2025-02-15T22:18:44.266673Z",
          "shell.execute_reply.started": "2025-02-15T22:18:44.196974Z",
          "shell.execute_reply": "2025-02-15T22:18:44.266037Z"
        },
        "id": "d7Op3aURko3d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# get statistics on numrical columns ( int or float )\n",
        "df_preprocessed.describe()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:18:44.267438Z",
          "iopub.execute_input": "2025-02-15T22:18:44.267756Z",
          "iopub.status.idle": "2025-02-15T22:18:44.946509Z",
          "shell.execute_reply.started": "2025-02-15T22:18:44.267725Z",
          "shell.execute_reply": "2025-02-15T22:18:44.945686Z"
        },
        "id": "sF4Qp_u3ko3e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_preprocessed.duplicated().sum())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:18:44.948455Z",
          "iopub.execute_input": "2025-02-15T22:18:44.948676Z",
          "iopub.status.idle": "2025-02-15T22:18:45.458792Z",
          "shell.execute_reply.started": "2025-02-15T22:18:44.948656Z",
          "shell.execute_reply": "2025-02-15T22:18:45.457791Z"
        },
        "id": "BdofknQOko3e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_preprocessed.dtypes"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:18:45.459834Z",
          "iopub.execute_input": "2025-02-15T22:18:45.460136Z",
          "iopub.status.idle": "2025-02-15T22:18:45.465993Z",
          "shell.execute_reply.started": "2025-02-15T22:18:45.460114Z",
          "shell.execute_reply": "2025-02-15T22:18:45.465093Z"
        },
        "id": "Lcdl6Jarko3e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df_preprocessed.drop('is_fraud', axis=1)\n",
        "y_train = df_preprocessed['is_fraud']\n",
        "X_test = t_df_preprocessed.drop('is_fraud', axis=1)\n",
        "y_test = t_df_preprocessed['is_fraud']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:18:48.848182Z",
          "iopub.execute_input": "2025-02-15T22:18:48.84852Z",
          "iopub.status.idle": "2025-02-15T22:18:48.907636Z",
          "shell.execute_reply.started": "2025-02-15T22:18:48.848494Z",
          "shell.execute_reply": "2025-02-15T22:18:48.906904Z"
        },
        "id": "aDkeTW_Kko3f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA and Visualizations"
      ],
      "metadata": {
        "id": "i43bdOzyko3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### class Imbalance"
      ],
      "metadata": {
        "id": "Ltts4xL1ko3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.violinplot(x='is_fraud', y='amt', data=df_preprocessed, palette='coolwarm')\n",
        "plt.title('Violin Plot: Transaction Amount by Fraud')\n",
        "plt.xlabel('Is Fraud (1 = Fraud, 0 = Non-Fraud)')\n",
        "plt.ylabel('Transaction Amount')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T21:05:11.568092Z",
          "iopub.execute_input": "2025-02-15T21:05:11.568404Z",
          "iopub.status.idle": "2025-02-15T21:05:14.051501Z",
          "shell.execute_reply.started": "2025-02-15T21:05:11.568378Z",
          "shell.execute_reply": "2025-02-15T21:05:14.050699Z"
        },
        "id": "8paaWjwDko3f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# KDE Plot with Clear Labels\n",
        "plt.figure(figsize=(10, 6))\n",
        "kde_plot = sns.kdeplot(data=df_preprocessed,\n",
        "                       x='amt',\n",
        "                       hue='is_fraud',\n",
        "                       palette='coolwarm',\n",
        "                       fill=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T21:08:26.229085Z",
          "iopub.execute_input": "2025-02-15T21:08:26.229381Z",
          "iopub.status.idle": "2025-02-15T21:08:30.900747Z",
          "shell.execute_reply.started": "2025-02-15T21:08:26.22936Z",
          "shell.execute_reply": "2025-02-15T21:08:30.899808Z"
        },
        "id": "RjYdgLWako3f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Geospatial Analysis"
      ],
      "metadata": {
        "id": "OM94JHcMko3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot fraud incidents on a map\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.scatterplot(x='long', y='lat', hue='is_fraud', data=df, palette='coolwarm', alpha=0.6)\n",
        "plt.title('Geospatial Visualization of Fraud')\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.legend(title='Is Fraud', loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T21:05:58.7689Z",
          "iopub.execute_input": "2025-02-15T21:05:58.769188Z",
          "iopub.status.idle": "2025-02-15T21:06:22.166616Z",
          "shell.execute_reply.started": "2025-02-15T21:05:58.769165Z",
          "shell.execute_reply": "2025-02-15T21:06:22.165805Z"
        },
        "id": "gtJezk5Wko3g"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Temporal Analysis"
      ],
      "metadata": {
        "id": "Sdp-odmvko3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert transaction time to datetime\n",
        "#df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
        "\n",
        "# Group by date and calculate fraud count\n",
        "#fraud_over_time = df.groupby(df['trans_date_trans_time'].dt.date)['is_fraud'].sum()\n",
        "\n",
        "# Plot time series\n",
        "#plt.figure(figsize=(12, 6))\n",
        "#fraud_over_time.plot()\n",
        "#plt.title('Fraud Over Time')\n",
        "#plt.xlabel('Date')\n",
        "#plt.ylabel('Fraud Count')\n",
        "#plt.show()\n",
        "# Convert transaction time to datetime, handling errors and specifying format if necessary\n",
        "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'], errors='coerce', format='%Y-%m-%d %H:%M:%S')\n",
        "#The 'coerce' argument handles errors by setting invalid parsing to NaT (Not a Time)\n",
        "#The format argument is explicitly specified for consistency\n",
        "\n",
        "#If the format is not consistent, you might need to try:\n",
        "#df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'], errors='coerce', format='mixed')\n",
        "#or specify a different appropriate format.\n",
        "\n",
        "# Group by date and calculate fraud count\n",
        "fraud_over_time = df.groupby(df['trans_date_trans_time'].dt.date)['is_fraud'].sum()\n",
        "\n",
        "# Plot time series\n",
        "plt.figure(figsize=(12, 6))\n",
        "fraud_over_time.plot()\n",
        "plt.title('Fraud Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Fraud Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T21:09:32.590649Z",
          "iopub.execute_input": "2025-02-15T21:09:32.590967Z",
          "iopub.status.idle": "2025-02-15T21:09:33.561205Z",
          "shell.execute_reply.started": "2025-02-15T21:09:32.590942Z",
          "shell.execute_reply": "2025-02-15T21:09:33.560273Z"
        },
        "id": "YVxGBmklko3g"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Features"
      ],
      "metadata": {
        "id": "snKv3FV3ko3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transaction Amount, City Population, and Fraud"
      ],
      "metadata": {
        "id": "pKBl-6Gtko3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. 3D Scatter Plot: Transaction Amount, City Population, and Fraud\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Scatter plot\n",
        "scatter = ax.scatter(\n",
        "    df_preprocessed['amt'],\n",
        "    df_preprocessed['city_pop'],\n",
        "    df_preprocessed['is_fraud'],\n",
        "    c=df_preprocessed['is_fraud'],\n",
        "    cmap='coolwarm',\n",
        "    s=20\n",
        ")\n",
        "\n",
        "# Labels\n",
        "ax.set_xlabel('Transaction Amount (amt)')\n",
        "ax.set_ylabel('City Population')\n",
        "ax.set_zlabel('Is Fraud (1 = Fraud, 0 = Non-Fraud)')\n",
        "plt.title('3D Scatter Plot: Transaction Amount, City Population, and Fraud')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T21:07:05.859098Z",
          "iopub.execute_input": "2025-02-15T21:07:05.859399Z",
          "iopub.status.idle": "2025-02-15T21:07:28.839591Z",
          "shell.execute_reply.started": "2025-02-15T21:07:05.859374Z",
          "shell.execute_reply": "2025-02-15T21:07:28.838678Z"
        },
        "id": "eewuO048ko3g"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### City Population"
      ],
      "metadata": {
        "id": "8A0xdwpFko3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.kdeplot(data=df_preprocessed, x='city_pop', hue='is_fraud', palette='coolwarm', fill=True)\n",
        "plt.title('KDE Plot: City Population by Fraud')\n",
        "plt.xlabel('City Population')\n",
        "plt.ylabel('Density')\n",
        "plt.legend(title='Is Fraud', labels=['Non-Fraud (0)', 'Fraud (1)'])\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T21:07:59.799849Z",
          "iopub.execute_input": "2025-02-15T21:07:59.800128Z",
          "iopub.status.idle": "2025-02-15T21:08:04.671455Z",
          "shell.execute_reply.started": "2025-02-15T21:07:59.800107Z",
          "shell.execute_reply": "2025-02-15T21:08:04.67058Z"
        },
        "id": "iURwN8TDko3g"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate fraud proportion\n",
        "fraud_proportion = df['is_fraud'].value_counts(normalize=True)\n",
        "\n",
        "# Plot pie chart\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(fraud_proportion, labels=['Non-Fraud', 'Fraud'], autopct='%1.1f%%', colors=['lightblue', 'lightcoral'])\n",
        "plt.title('Proportion of Fraudulent vs Non-Fraudulent Transactions')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T21:10:02.527154Z",
          "iopub.execute_input": "2025-02-15T21:10:02.527457Z",
          "iopub.status.idle": "2025-02-15T21:10:02.638038Z",
          "shell.execute_reply.started": "2025-02-15T21:10:02.527432Z",
          "shell.execute_reply": "2025-02-15T21:10:02.6371Z"
        },
        "id": "1thILpnjko3h"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Distribution of Transaction Amount (amt)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df_preprocessed['amt'], bins=50, kde=True, color='blue')\n",
        "plt.title('Distribution of Transaction Amount (amt)')\n",
        "plt.xlabel('Transaction Amount')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T21:10:52.566578Z",
          "iopub.execute_input": "2025-02-15T21:10:52.566893Z",
          "iopub.status.idle": "2025-02-15T21:10:57.515382Z",
          "shell.execute_reply.started": "2025-02-15T21:10:52.56687Z",
          "shell.execute_reply": "2025-02-15T21:10:57.514566Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "VvDGropmko3h",
        "outputId": "79452cfe-bd3d-42b8-e661-414d3156a03c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ec31658e4d79>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Distribution of Transaction Amount (amt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkde\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Distribution of Transaction Amount (amt)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Transaction Amount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Distribution of City Population\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df_preprocessed['city_pop'], bins=50, kde=True, color='green')\n",
        "plt.title('Distribution of City Population')\n",
        "plt.xlabel('City Population')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T21:13:45.378187Z",
          "iopub.execute_input": "2025-02-15T21:13:45.378563Z",
          "iopub.status.idle": "2025-02-15T21:13:50.630354Z",
          "shell.execute_reply.started": "2025-02-15T21:13:45.378534Z",
          "shell.execute_reply": "2025-02-15T21:13:50.629538Z"
        },
        "id": "JsNYZn7wko3h"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fraud Distribution by Gender\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='gender', hue='is_fraud', data=df_preprocessed, palette='coolwarm')\n",
        "plt.title('Fraud Distribution by Gender')\n",
        "plt.xlabel('Gender (1 = Male, 0 = Female)')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Is Fraud', loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T21:13:54.043347Z",
          "iopub.execute_input": "2025-02-15T21:13:54.043689Z",
          "iopub.status.idle": "2025-02-15T21:13:54.335433Z",
          "shell.execute_reply.started": "2025-02-15T21:13:54.043663Z",
          "shell.execute_reply": "2025-02-15T21:13:54.334533Z"
        },
        "id": "hu7w0-G2ko3h"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlation Matrix"
      ],
      "metadata": {
        "id": "NvbBLuKgko3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Correlation Heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "corr = df_preprocessed.corr()\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T21:14:16.992556Z",
          "iopub.execute_input": "2025-02-15T21:14:16.992862Z",
          "iopub.status.idle": "2025-02-15T21:14:18.271929Z",
          "shell.execute_reply.started": "2025-02-15T21:14:16.99284Z",
          "shell.execute_reply": "2025-02-15T21:14:18.270997Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "UQV7No4Lko3h",
        "outputId": "bf471ec2-d38b-45d5-d5c9-98bb79b48069"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-dd0ebccf8b32>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Correlation Heatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_preprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coolwarm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.2f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Correlation Heatmap'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply NearMiss Undersampling"
      ],
      "metadata": {
        "id": "YXnwUxnIko3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nm = NearMiss(version=1)\n",
        "# X_resampled, y_resampled = nm.fit_resample(X_train, y_train)\n",
        "\n",
        "# print(\"Class distribution after NearMiss:\", Counter(y_resampled))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ylisj_5Qko3h"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Apply SMOTE Oversampling"
      ],
      "metadata": {
        "id": "K9PMQlXuko3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from imblearn.over_sampling import SMOTE\n",
        "#from collections import Counter\n",
        "\n",
        "# Check class distribution before applying SMOTE\n",
        "#print(\"Class distribution before SMOTE:\", Counter(y_train))\n",
        "\n",
        "# Apply SMOTE with a sampling strategy that makes sense based on class distribution\n",
        "#smote = SMOTE(sampling_strategy='auto', random_state=42)  # Balances both classes equally\n",
        "#X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Check the new class distribution after applying SMOTE\n",
        "#print(\"Class distribution after SMOTE:\", Counter(y_train_balanced))\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# Check class distribution before applying SMOTE\n",
        "print(\"Class distribution before SMOTE:\", Counter(y_train))\n",
        "\n",
        "# Drop rows with NaN values in y_train and corresponding rows in X_train\n",
        "# Get the indices of rows with NaN values in y_train\n",
        "nan_indices = y_train[y_train.isnull()].index\n",
        "\n",
        "# Drop those rows from both X_train and y_train\n",
        "X_train = X_train.drop(index=nan_indices)\n",
        "y_train = y_train.drop(index=nan_indices)\n",
        "\n",
        "# Apply SMOTE with a sampling strategy that makes sense based on class distribution\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)  # Balances both classes equally\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Check the new class distribution after applying SMOTE\n",
        "print(\"Class distribution after SMOTE:\", Counter(y_train_balanced))\n"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "sDSogWW5ko3i",
        "outputId": "ed52b41e-a6d5-495f-bb4e-f4f1faa7e4f7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-f1b7d4273e6c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Check class distribution before applying SMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Class distribution before SMOTE:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Drop rows with NaN values in y_train and corresponding rows in X_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train_balanced.value_counts())\n",
        "sns.countplot(x=y_train_balanced)\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "mfj4Qgx_ko3i"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Models"
      ],
      "metadata": {
        "id": "b_NdLjUnko3i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Isolation Forest\n",
        "Isolates anomalies by randomly splitting the data."
      ],
      "metadata": {
        "id": "DRSmO8-8ko3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#iso_forest = IsolationForest(contamination=0.02, random_state=42)\n",
        "\n",
        "# Train and predict on training set\n",
        "#iso_forest.fit(X_train)\n",
        "#train_pred = iso_forest.predict(X_train)\n",
        "#train_pred = np.where(train_pred == -1, 1, 0)  # Convert -1 (outlier) to 1, 0 (inlier) to 0\n",
        "\n",
        "# Predict on test set\n",
        "#test_pred = iso_forest.predict(X_test)\n",
        "#test_pred = np.where(test_pred == -1, 1, 0)\n",
        "\n",
        "# Calculate accuracy\n",
        "#train_accuracy = accuracy_score(y_train, train_pred)\n",
        "#test_accuracy = accuracy_score(y_test, test_pred)\n",
        "\n",
        "# Print results\n",
        "#print(\"Isolation Forest - Train Accuracy: {:.4f}\".format(train_accuracy))\n",
        "#print(\"Isolation Forest - Test Accuracy: {:.4f}\".format(test_accuracy))\n",
        "#print(\"Classification Report for Test Set:\")\n",
        "#print(classification_report(y_test, test_pred))# ... (your existing code) ...\n",
        "#iso_forest = IsolationForest(contamination=0.02, random_state=42)\n",
        "\n",
        "# Train and predict on training set\n",
        "#iso_forest.fit(X_train)\n",
        "#train_pred = iso_forest.predict(X_train)\n",
        "#train_pred = np.where(train_pred == -1, 1, 0)  # Convert -1 (outlier) to 1, 0 (inlier) to 0\n",
        "\n",
        "# Predict on test set\n",
        "#test_pred = iso_forest.predict(X_test)\n",
        "#test_pred = np.where(test_pred == -1, 1, 0)\n",
        "\n",
        "# Calculate accuracy\n",
        "#train_accuracy = accuracy_score(y_train, train_pred)\n",
        "#test_accuracy = accuracy_score(y_test, test_pred)\n",
        "\n",
        "# Print results\n",
        "#print(\"Isolation Forest - Train Accuracy: {:.4f}\".format(train_accuracy))\n",
        "#print(\"Isolation Forest - Test Accuracy: {:.4f}\".format(test_accuracy))\n",
        "#print(\"Classification Report for Test Set:\")\n",
        "#print(classification_report(y_test, test_pred))# ... (your existing code) ...\n",
        "# ... (your existing code) ...\n",
        "\n",
        "# ... (your existing code) ...\n",
        "\n",
        "# Check and handle NaN values in y_test before calculating accuracy\n",
        "if y_test.isnull().any():\n",
        "    # Option 1: Remove rows with NaN values from both X_test and y_test\n",
        "    nan_indices = y_test[y_test.isnull()].index\n",
        "    X_test = X_test.drop(index=nan_indices)\n",
        "    y_test = y_test.drop(index=nan_indices)\n",
        "\n",
        "    print(\"Removed rows with NaN values from X_test and y_test.\")\n",
        "else:\n",
        "    print(\"No NaN values found in y_test.\")\n",
        "\n",
        "# Train and predict on training set using Isolation Forest with balanced data\n",
        "iso_forest = IsolationForest(contamination=0.02, random_state=42)  # Define iso_forest here\n",
        "iso_forest.fit(X_train_balanced)  # Use balanced data for training\n",
        "train_pred = iso_forest.predict(X_train_balanced)  # Use balanced data for prediction\n",
        "train_pred = np.where(train_pred == -1, 1, 0)  # Convert -1 (outlier) to 1, 0 (inlier) to 0\n",
        "\n",
        "# Calculate accuracy using the balanced training data and predictions\n",
        "train_accuracy = accuracy_score(y_train_balanced, train_pred)  # Use y_train_balanced\n",
        "\n",
        "# Predict on test set and convert predictions\n",
        "test_pred = iso_forest.predict(X_test)  # Predict on the test data\n",
        "test_pred = np.where(test_pred == -1, 1, 0)  # Convert predictions to 0 and 1\n",
        "\n",
        "# Ensure test_pred and y_test have the same length\n",
        "# The line below is not needed as the predict function will generate values matching the X_test input\n",
        "#test_pred = test_pred[:len(y_test)]  # Truncate test_pred to match y_test length\n",
        "\n",
        "# Now you can calculate the test accuracy\n",
        "test_accuracy = accuracy_score(y_test, test_pred)\n",
        "\n",
        "# ... (rest of your code) ..."
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T21:15:37.725571Z",
          "iopub.execute_input": "2025-02-15T21:15:37.725885Z",
          "iopub.status.idle": "2025-02-15T21:17:14.017006Z",
          "shell.execute_reply.started": "2025-02-15T21:15:37.725861Z",
          "shell.execute_reply": "2025-02-15T21:17:14.015995Z"
        },
        "id": "89ky3YEHko3p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, test_pred)\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Non-Fraud', 'Fraud'],\n",
        "            yticklabels=['Non-Fraud', 'Fraud'])\n",
        "plt.title('Confusion Matrix for Isolation Forest')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T21:25:28.322339Z",
          "iopub.execute_input": "2025-02-15T21:25:28.322799Z",
          "iopub.status.idle": "2025-02-15T21:25:28.880071Z",
          "shell.execute_reply.started": "2025-02-15T21:25:28.322763Z",
          "shell.execute_reply": "2025-02-15T21:25:28.879108Z"
        },
        "id": "77bROm3Nko3p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Get anomaly scores from Isolation Forest\n",
        "test_scores = iso_forest.decision_function(X_test)\n",
        "# Calculate ROC curve and AUC score\n",
        "fpr, tpr, thresholds = roc_curve(y_test, -test_scores)\n",
        "auc_score = roc_auc_score(y_test, -test_scores)\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.title('ROC Curve for Isolation Forest')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T21:23:43.420172Z",
          "iopub.execute_input": "2025-02-15T21:23:43.420541Z",
          "iopub.status.idle": "2025-02-15T21:23:58.083756Z",
          "shell.execute_reply.started": "2025-02-15T21:23:43.420507Z",
          "shell.execute_reply": "2025-02-15T21:23:58.08279Z"
        },
        "id": "29Yv25h4ko3p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Local Outlier Factor (LOF)\n",
        "Compares local density of a point to its neighbors."
      ],
      "metadata": {
        "id": "qKpUflIGko3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lof = LocalOutlierFactor(contamination=0.02)\n",
        "\n",
        "# Predict on training set\n",
        "train_pred = lof.fit_predict(X_train)\n",
        "train_pred = np.where(train_pred == -1, 1, 0)\n",
        "\n",
        "# Predict on test set\n",
        "test_pred = lof.fit_predict(X_test)\n",
        "test_pred = np.where(test_pred == -1, 1, 0)\n",
        "\n",
        "# Calculate accuracy\n",
        "train_accuracy = accuracy_score(y_train, train_pred)\n",
        "test_accuracy = accuracy_score(y_test, test_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Local Outlier Factor (LOF) - Train Accuracy: {:.4f}\".format(train_accuracy))\n",
        "print(\"Local Outlier Factor (LOF) - Test Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Classification Report for Test Set:\")\n",
        "print(classification_report(y_test, test_pred))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T21:28:49.053728Z",
          "iopub.execute_input": "2025-02-15T21:28:49.054052Z",
          "iopub.status.idle": "2025-02-15T21:32:59.134085Z",
          "shell.execute_reply.started": "2025-02-15T21:28:49.054028Z",
          "shell.execute_reply": "2025-02-15T21:32:59.133087Z"
        },
        "id": "WDQqyRu8ko3q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, test_pred)\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Non-Fraud', 'Fraud'],\n",
        "            yticklabels=['Non-Fraud', 'Fraud'])\n",
        "plt.title('Confusion Matrix for Local Outlier Factor (LOF)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T21:33:15.590531Z",
          "iopub.execute_input": "2025-02-15T21:33:15.590827Z",
          "iopub.status.idle": "2025-02-15T21:33:16.14674Z",
          "shell.execute_reply.started": "2025-02-15T21:33:15.590805Z",
          "shell.execute_reply": "2025-02-15T21:33:16.145859Z"
        },
        "id": "Zays5pbrko3q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Get negative outlier factor scores for the test set\n",
        "test_scores = -lof.negative_outlier_factor_\n",
        "# Calculate ROC curve and AUC score\n",
        "fpr, tpr, thresholds = roc_curve(y_test, test_scores)\n",
        "auc_score = roc_auc_score(y_test, test_scores)\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.title('ROC Curve for Local Outlier Factor (LOF)')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T21:33:25.606527Z",
          "iopub.execute_input": "2025-02-15T21:33:25.606832Z",
          "iopub.status.idle": "2025-02-15T21:33:26.201114Z",
          "shell.execute_reply.started": "2025-02-15T21:33:25.606809Z",
          "shell.execute_reply": "2025-02-15T21:33:26.200278Z"
        },
        "id": "DZAiuK3nko3q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-Class SVM\n",
        "Learns a boundary around normal data points."
      ],
      "metadata": {
        "id": "u2FT2Mlmko3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Takes too loooooooooooong to run\n",
        "one_class_svm = OneClassSVM(nu=0.02)\n",
        "\n",
        "# Train and predict on training set\n",
        "one_class_svm.fit(X_train)\n",
        "train_pred = one_class_svm.predict(X_train)\n",
        "train_pred = np.where(train_pred == -1, 1, 0)\n",
        "\n",
        "# Predict on test set\n",
        "test_pred = one_class_svm.predict(X_test)\n",
        "test_pred = np.where(test_pred == -1, 1, 0)\n",
        "\n",
        "# Calculate accuracy\n",
        "train_accuracy = accuracy_score(y_train, train_pred)\n",
        "test_accuracy = accuracy_score(y_test, test_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"One-Class SVM - Train Accuracy: {:.4f}\".format(train_accuracy))\n",
        "print(\"One-Class SVM - Test Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Classification Report for Test Set:\")\n",
        "print(classification_report(y_test, test_pred))"
      ],
      "metadata": {
        "trusted": true,
        "id": "dL9Tfs5yko3q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, test_pred)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Non-Fraud', 'Fraud'],\n",
        "            yticklabels=['Non-Fraud', 'Fraud'])\n",
        "plt.title('Confusion Matrix for One-Class SVM')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "uzEBFUs3ko3q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_scores = one_class_svm.decision_function(X_test)\n",
        "# Calculate ROC curve and AUC score\n",
        "fpr, tpr, thresholds = roc_curve(y_test, -test_scores)  # Use negative scores to align with ROC curve convention\n",
        "auc_score = roc_auc_score(y_test, -test_scores)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.title('ROC Curve for One-Class SVM')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "c1SApID4ko3q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DBSCAN\n",
        "Groups data into clusters; points not in any cluster are outliers."
      ],
      "metadata": {
        "id": "sq6vAQLzko3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dbscan = DBSCAN(eps=0.5, min_samples=10)\n",
        "# Predict on training set\n",
        "train_pred = dbscan.fit_predict(X_train)\n",
        "train_pred = np.where(train_pred == -1, 1, 0)\n",
        "\n",
        "# Predict on test set\n",
        "test_pred = dbscan.fit_predict(X_test)\n",
        "test_pred = np.where(test_pred == -1, 1, 0)\n",
        "\n",
        "# Calculate accuracy\n",
        "train_accuracy = accuracy_score(y_train, train_pred)\n",
        "test_accuracy = accuracy_score(y_test, test_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"DBSCAN - Train Accuracy: {:.4f}\".format(train_accuracy))\n",
        "print(\"DBSCAN - Test Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Classification Report for Test Set:\")\n",
        "print(classification_report(y_test, test_pred))"
      ],
      "metadata": {
        "trusted": true,
        "id": "U-oHl-qgko3q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "7240e194-8089-4531-f372-e65fb2ef7a7c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'DBSCAN' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d7d04a5be7fe>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdbscan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Predict on training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbscan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DBSCAN' is not defined"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, test_pred)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Non-Fraud', 'Fraud'],\n",
        "            yticklabels=['Non-Fraud', 'Fraud'])\n",
        "plt.title('Confusion Matrix for DBSCAN')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "DzzsWjZako3r"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the distance to the nearest core point\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "# Fit NearestNeighbors on the training set\n",
        "nbrs = NearestNeighbors(n_neighbors=10).fit(X_train)\n",
        "# Calculate distances for the test set\n",
        "distances, _ = nbrs.kneighbors(X_test)\n",
        "test_scores = -np.mean(distances, axis=1)  # Use negative distances as anomaly scores\n",
        "# Calculate ROC curve and AUC score\n",
        "fpr, tpr, thresholds = roc_curve(y_test, test_scores)\n",
        "auc_score = roc_auc_score(y_test, test_scores)\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.title('ROC Curve for DBSCAN')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "yl2Sk2fPko3r"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Models"
      ],
      "metadata": {
        "id": "Live7Jg6ko3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoencoders\n",
        " learning to reconstruct normal data. Anomalies are detected based on high reconstruction errors."
      ],
      "metadata": {
        "id": "FkNiMJp_ko3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = X_train.shape[1]\n",
        "\n",
        "# Encoder\n",
        "encoder_input = layers.Input(shape=(input_dim,))\n",
        "encoded = layers.Dense(8, activation=\"relu\")(encoder_input)\n",
        "encoded = layers.Dense(4, activation=\"relu\")(encoded)\n",
        "\n",
        "# Decoder\n",
        "decoded = layers.Dense(8, activation=\"relu\")(encoded)\n",
        "decoded = layers.Dense(input_dim, activation=\"sigmoid\")(decoded)\n",
        "\n",
        "# Define autoencoder model\n",
        "autoencoder = models.Model(inputs=encoder_input, outputs=decoded)\n",
        "\n",
        "# Compile Autoencoder\n",
        "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "# Train Autoencoder\n",
        "autoencoder.fit(X_train, X_train, epochs=20, batch_size=32, shuffle=True, validation_data=(X_test, X_test))\n",
        "\n",
        "# Compute reconstruction errors\n",
        "train_reconstructed = autoencoder.predict(X_train)\n",
        "train_mse = np.mean(np.power(X_train - train_reconstructed, 2), axis=1)\n",
        "\n",
        "test_reconstructed = autoencoder.predict(X_test)\n",
        "test_mse = np.mean(np.power(X_test - test_reconstructed, 2), axis=1)\n",
        "\n",
        "# Set threshold for anomaly detection (95th percentile of training MSE)\n",
        "threshold = np.percentile(train_mse, 95)\n",
        "\n",
        "# Predict anomalies\n",
        "train_pred = (train_mse > threshold).astype(int)\n",
        "test_pred = (test_mse > threshold).astype(int)\n",
        "\n",
        "# Calculate accuracy\n",
        "train_accuracy = accuracy_score(y_train, train_pred)\n",
        "test_accuracy = accuracy_score(y_test, test_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Autoencoder - Train Accuracy: {:.4f}\".format(train_accuracy))\n",
        "print(\"Autoencoder - Test Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Classification Report for Test Set:\")\n",
        "print(classification_report(y_test, test_pred))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:19:08.217602Z",
          "iopub.execute_input": "2025-02-15T22:19:08.217918Z",
          "iopub.status.idle": "2025-02-15T22:42:45.696479Z",
          "shell.execute_reply.started": "2025-02-15T22:19:08.217889Z",
          "shell.execute_reply": "2025-02-15T22:42:45.695653Z"
        },
        "id": "zoP3JukDko3r"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, test_pred)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Non-Fraud', 'Fraud'],\n",
        "            yticklabels=['Non-Fraud', 'Fraud'])\n",
        "plt.title('Confusion Matrix for Autoencoder')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T22:44:59.71482Z",
          "iopub.execute_input": "2025-02-15T22:44:59.71518Z",
          "iopub.status.idle": "2025-02-15T22:45:00.404271Z",
          "shell.execute_reply.started": "2025-02-15T22:44:59.715151Z",
          "shell.execute_reply": "2025-02-15T22:45:00.403408Z"
        },
        "id": "raUAtOgqko3r"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-Class Neural Networks (OC-NN)"
      ],
      "metadata": {
        "id": "2Xg2QB3Yko3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are already defined\n",
        "\n",
        "# Define input dimension\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "# Define the One-Class Neural Network (OC-NN)\n",
        "inputs = Input(shape=(input_dim,))\n",
        "x = Dense(64, activation='relu')(inputs)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "oc_nn = Model(inputs, outputs)\n",
        "oc_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = oc_nn.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = oc_nn.predict(X_test)\n",
        "y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
        "\n",
        "# Calculate accuracy\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T23:20:13.248671Z",
          "iopub.execute_input": "2025-02-15T23:20:13.248984Z",
          "iopub.status.idle": "2025-02-15T23:37:07.75728Z",
          "shell.execute_reply.started": "2025-02-15T23:20:13.248928Z",
          "shell.execute_reply": "2025-02-15T23:37:07.756308Z"
        },
        "id": "ndViOcFnko3r"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Non-Fraud', 'Fraud'],\n",
        "            yticklabels=['Non-Fraud', 'Fraud'])\n",
        "plt.title('Confusion Matrix for OC-NN')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Non-Fraud', 'Fraud']))"
      ],
      "metadata": {
        "trusted": true,
        "id": "vtH_rYWgko3r"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Support Vector Data Description (Deep SVDD)"
      ],
      "metadata": {
        "id": "aLD4s1Nwko3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are already defined\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define input dimension\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "# Define the Deep SVDD model with increased capacity and dropout\n",
        "inputs = Input(shape=(input_dim,))\n",
        "x = Dense(128, activation='relu')(inputs)  # Increased neurons\n",
        "x = Dropout(0.5)(x)  # Dropout for regularization\n",
        "x = Dense(64, activation='relu')(x)  # Additional layer\n",
        "x = Dropout(0.5)(x)  # Dropout for regularization\n",
        "outputs = Dense(1, activation='linear')(x)\n",
        "\n",
        "deep_svdd = Model(inputs, outputs)\n",
        "\n",
        "# Compile the model with a different loss function and learning rate\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "deep_svdd.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "# Train the model without early stopping\n",
        "history = deep_svdd.fit(X_train, X_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_scores = deep_svdd.predict(X_test)\n",
        "\n",
        "# Set a lower threshold for anomaly detection (e.g., 90th percentile)\n",
        "train_scores = deep_svdd.predict(X_train)\n",
        "threshold = np.percentile(train_scores, 90)  # Lower threshold to reduce false negatives\n",
        "\n",
        "# Predict anomalies\n",
        "test_pred = (test_scores > threshold).astype(int)\n",
        "\n",
        "# Calculate accuracy\n",
        "test_accuracy = accuracy_score(y_test, test_pred)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-16T00:58:32.106562Z",
          "iopub.execute_input": "2025-02-16T00:58:32.106912Z",
          "iopub.status.idle": "2025-02-16T01:07:50.865361Z",
          "shell.execute_reply.started": "2025-02-16T00:58:32.106872Z",
          "shell.execute_reply": "2025-02-16T01:07:50.864544Z"
        },
        "id": "qp-zZ_-9ko3s"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, test_pred)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Non-Fraud', 'Fraud'],\n",
        "            yticklabels=['Non-Fraud', 'Fraud'])\n",
        "plt.title('Confusion Matrix for Deep SVDD')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, test_pred, target_names=['Non-Fraud', 'Fraud']))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-16T01:43:45.992427Z",
          "iopub.execute_input": "2025-02-16T01:43:45.992722Z",
          "iopub.status.idle": "2025-02-16T01:43:45.996075Z",
          "shell.execute_reply.started": "2025-02-16T01:43:45.9927Z",
          "shell.execute_reply": "2025-02-16T01:43:45.995379Z"
        },
        "id": "Y4yu69gJko3s"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# visualize to compare Models  "
      ],
      "metadata": {
        "id": "9tnZlR01ko3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Model names\n",
        "models = [\"Isolation Forest\", \"Local Outlier Factor\", \"Autoencoder\", \"OC-NN\", \"Deep SVDD\"]\n",
        "\n",
        "# Accuracy scores\n",
        "train_accuracy = [0.9750, 0.9759, 0.9453, 1.00, 1.00]\n",
        "test_accuracy = [0.9753, 0.9768, 0.9461, 1.00, 0.89]\n",
        "\n",
        "# Precision scores (Fraud class)\n",
        "precision = [0.01, 0.02, 0.01, 0.83, 0.01]\n",
        "\n",
        "# Recall scores (Fraud class)\n",
        "recall = [0.08, 0.08, 0.11, 0.13, 0.28]\n",
        "\n",
        "# F1-score (Fraud class)\n",
        "f1_score = [0.02, 0.03, 0.02, 0.22, 0.02]\n",
        "\n",
        "# Bar chart settings\n",
        "bar_width = 0.15\n",
        "index = np.arange(len(models))\n",
        "\n",
        "# Plot accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(index, train_accuracy, bar_width, label='Train Accuracy', color='blue')\n",
        "plt.bar(index + bar_width, test_accuracy, bar_width, label='Test Accuracy', color='cyan')\n",
        "plt.bar(index + 2 * bar_width, precision, bar_width, label='Precision (Fraud)', color='green')\n",
        "plt.bar(index + 3 * bar_width, recall, bar_width, label='Recall (Fraud)', color='red')\n",
        "plt.bar(index + 4 * bar_width, f1_score, bar_width, label='F1-Score (Fraud)', color='purple')\n",
        "\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Performance Comparison of Fraud Detection Models')\n",
        "plt.xticks(index + 2 * bar_width, models, rotation=15)\n",
        "plt.legend()\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-16T01:33:45.353214Z",
          "iopub.execute_input": "2025-02-16T01:33:45.353563Z",
          "iopub.status.idle": "2025-02-16T01:33:45.621124Z",
          "shell.execute_reply.started": "2025-02-16T01:33:45.353533Z",
          "shell.execute_reply": "2025-02-16T01:33:45.620298Z"
        },
        "id": "NsPxCFmbko3s"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ROC Curves (For Each Model)\n",
        "#### need edit"
      ],
      "metadata": {
        "id": "7S04Rw1Zko3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.metrics import roc_curve, auc\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "# Replace with actual values from each model\n",
        "#models = {\n",
        "    #\"Isolation Forest\": isolation_forest_predictions_proba,\n",
        "    #\"Local Outlier Factor\": lof_predictions_proba,\n",
        "   # \"Autoencoder\": autoencoder_predictions_proba,\n",
        "  #  \"OC-NN\": oc_nn_predictions_proba,\n",
        " #   \"Deep SVDD\": deep_svdd_predictions_proba\n",
        "#}\n",
        "\n",
        "#plt.figure(figsize=(8, 6))\n",
        "\n",
        "#for model_name, y_scores in models.items():\n",
        "   # fpr, tpr, _ = roc_curve(y_true, y_scores)  # Use real labels\n",
        "  #  roc_auc = auc(fpr, tpr)\n",
        " #   plt.plot(fpr, tpr, label=f\"{model_name} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "#plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Random baseline\n",
        "#plt.xlabel('False Positive Rate')\n",
        "#plt.ylabel('True Positive Rate')\n",
        "#plt.title('ROC Curve for Fraud Detection Models')\n",
        "#plt.legend()\n",
        "#plt.grid(True)\n",
        "#plt.show()\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get predicted probabilities for each model\n",
        "isolation_forest_predictions_proba = iso_forest.decision_function(X_test)\n",
        "lof_predictions_proba = -lof.negative_outlier_factor_  # Use negative outlier factor as scores\n",
        "# For autoencoder, use reconstruction error as anomaly score\n",
        "autoencoder_predictions_proba = test_mse\n",
        "oc_nn_predictions_proba = oc_nn.predict(X_test).ravel()\n",
        "deep_svdd_predictions_proba = deep_svdd.predict(X_test).ravel()\n",
        "\n",
        "\n",
        "models = {\n",
        "    \"Isolation Forest\": isolation_forest_predictions_proba,\n",
        "    \"Local Outlier Factor\": lof_predictions_proba,\n",
        "    \"Autoencoder\": autoencoder_predictions_proba,\n",
        "    \"OC-NN\": oc_nn_predictions_proba,\n",
        "    \"Deep SVDD\": deep_svdd_predictions_proba\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "for model_name, y_scores in models.items():\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_scores)  # Use real labels\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f\"{model_name} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Random baseline\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Fraud Detection Models')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-16T01:41:16.56066Z",
          "iopub.execute_input": "2025-02-16T01:41:16.560971Z",
          "iopub.status.idle": "2025-02-16T01:41:16.564629Z",
          "shell.execute_reply.started": "2025-02-16T01:41:16.560927Z",
          "shell.execute_reply": "2025-02-16T01:41:16.563755Z"
        },
        "id": "BeGOpz4Tko3s"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Confusion Matrices\n",
        "#### need edit"
      ],
      "metadata": {
        "id": "OAE3rVE6ko3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "#odels_predictions = {\n",
        "\n",
        " #   \"Isolation Forest\": isolation_forest_predictions,\n",
        "    #\"Local Outlier Factor\": lof_predictions,\n",
        "   # \"Autoencoder\": autoencoder_predictions,\n",
        "  #  \"OC-NN\": oc_nn_predictions,\n",
        " #   \"Deep SVDD\": deep_svdd_predictions\n",
        "#}\n",
        "\n",
        "#for model_name, y_pred in models_predictions.items():\n",
        "   # cm = confusion_matrix(y_true, y_pred)\n",
        "   # plt.figure(figsize=(6, 6))\n",
        "   # disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Non-Fraud\", \"Fraud\"])\n",
        "   # disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "   # plt.title(f\"Confusion Matrix - {model_name}\")\n",
        "  #  plt.show()\n",
        "\n",
        "#from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "#odels_predictions = {\n",
        "\n",
        " #   \"Isolation Forest\": isolation_forest_predictions,\n",
        "    #\"Local Outlier Factor\": lof_predictions,\n",
        "   # \"Autoencoder\": autoencoder_predictions,\n",
        "  #  \"OC-NN\": oc_nn_predictions,\n",
        " #   \"Deep SVDD\": deep_svdd_predictions\n",
        "#}\n",
        "\n",
        "#for model_name, y_pred in models_predictions.items():\n",
        "   # cm = confusion_matrix(y_true, y_pred)\n",
        "   # plt.figure(figsize=(6, 6))\n",
        "   # disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Non-Fraud\", \"Fraud\"])\n",
        "   # disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "   # plt.title(f\"Confusion Matrix - {model_name}\")\n",
        "  #  plt.show()\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay #Fixed indentation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have the following predictions from previous model runs:\n",
        "# isolation_forest_predictions, lof_predictions, autoencoder_predictions, oc_nn_predictions, deep_svdd_predictions\n",
        "\n",
        "# Store predictions in a dictionary (Replace with actual predictions)\n",
        "# Replace these with the actual predictions you calculated earlier\n",
        "isolation_forest_predictions = iso_forest.predict(X_test)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-16T01:35:53.279053Z",
          "iopub.execute_input": "2025-02-16T01:35:53.279361Z",
          "iopub.status.idle": "2025-02-16T01:35:53.47151Z",
          "shell.execute_reply.started": "2025-02-16T01:35:53.279339Z",
          "shell.execute_reply": "2025-02-16T01:35:53.470811Z"
        },
        "id": "B5zhxH53ko3s"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Precision-Recall Curves\n",
        "#### need edit"
      ],
      "metadata": {
        "id": "tQ77x_h_ko3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "#plt.figure(figsize=(8, 6))\n",
        "\n",
        "#for model_name, y_scores in models.items():\n",
        "  #  precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
        " #   plt.plot(recall, precision, label=f\"{model_name}\")\n",
        "\n",
        "#plt.xlabel('Recall')\n",
        "#plt.ylabel('Precision')\n",
        "#plt.title('Precision-Recall Curve for Fraud Detection Models')\n",
        "#plt.legend()\n",
        "#plt.grid(True)\n",
        "#plt.show()\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "for model_name, y_scores in models.items():\n",
        "    # Replace y_true with y_test\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
        "    plt.plot(recall, precision, label=f\"{model_name}\")\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve for Fraud Detection Models')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-16T01:41:03.305362Z",
          "iopub.execute_input": "2025-02-16T01:41:03.305671Z",
          "iopub.status.idle": "2025-02-16T01:41:03.30924Z",
          "shell.execute_reply.started": "2025-02-16T01:41:03.305647Z",
          "shell.execute_reply": "2025-02-16T01:41:03.308159Z"
        },
        "id": "VbRvLy6dko3t"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dash Board"
      ],
      "metadata": {
        "id": "BJGs_gNGko3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deployment"
      ],
      "metadata": {
        "id": "EiyOTuu9ko3t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "nglmchkAko3t"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}